{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from itertools import product\n",
    "import numpy as np\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "indir = Path(\"/home/nico/Software/nf-core/tfactivity/testing/work/82/d26ec8c82550eedc7e354a5b166ed1\")\n",
    "assets_dir = Path(\"src/assets\")\n",
    "public_dir = Path(\"public\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_design_path = indir / \"samplesheet_rnaseq.csv\"\n",
    "assert counts_design_path.exists()\n",
    "\n",
    "params_path = indir / \"params.yaml\"\n",
    "assert params_path.exists()\n",
    "\n",
    "affinity_ratio_dir = indir / \"affinity_ratio\"\n",
    "assert affinity_ratio_dir.exists()\n",
    "\n",
    "affinity_sum_dir = indir / \"affinity_sum\"\n",
    "assert affinity_sum_dir.exists()\n",
    "\n",
    "affinities_dir = indir / \"affinities\"\n",
    "assert affinities_dir.exists()\n",
    "\n",
    "deseq2_differential_dir = indir / \"deseq2_differential\"\n",
    "assert deseq2_differential_dir.exists()\n",
    "\n",
    "normalized_counts_dir = indir / \"normalized\"\n",
    "assert normalized_counts_dir.exists()\n",
    "\n",
    "raw_counts_dir = indir / \"raw_counts\"\n",
    "assert raw_counts_dir.exists()\n",
    "\n",
    "regression_coefficients_dir = indir / \"regression_coefficients\"\n",
    "assert regression_coefficients_dir.exists()\n",
    "\n",
    "tf_ranking_dir = indir / \"tf_rankings\"\n",
    "assert tf_ranking_dir.exists()\n",
    "\n",
    "tg_ranking_dir = indir / \"tg_rankings\"\n",
    "assert tg_ranking_dir.exists()\n",
    "\n",
    "tpm_dir = indir / \"tpms\"\n",
    "assert tpm_dir.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_26974/1292875757.py:3: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  \"conditions\": df_design.groupby(\"condition\").apply(lambda x: x[\"sample\"].tolist()).to_dict()\n"
     ]
    }
   ],
   "source": [
    "df_design = pd.read_csv(counts_design_path)\n",
    "metadata = {\n",
    "    \"conditions\": df_design.groupby(\"condition\").apply(lambda x: x[\"sample\"].tolist()).to_dict()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = yaml.load(open(params_path), yaml.CSafeLoader)\n",
    "json.dump(params, open(assets_dir / \"params.json\", \"w\"), indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking = {}\n",
    "tfs = {}\n",
    "\n",
    "pairings = set()\n",
    "\n",
    "for file in tf_ranking_dir.glob(\"*.tf_ranking.tsv\"):\n",
    "    assay = file.stem.split(\".\")[0]\n",
    "    \n",
    "    df_tf = pd.read_csv(file, sep=\"\\t\", index_col=0)\n",
    "    ranking[assay] = df_tf[\"dcg\"].to_dict()\n",
    "\n",
    "    df_tg = pd.read_csv(tg_ranking_dir / f\"{assay}.tg_ranking.tsv\", sep=\"\\t\", index_col=0)\n",
    "\n",
    "    for tf in df_tf.index:\n",
    "        if tf not in tfs:\n",
    "            tfs[tf] = {\n",
    "                \"target_genes\": {},\n",
    "                \"differential_expression\": {},\n",
    "                \"tg_affinities\": {},\n",
    "                \"affinity_ratio\": {},\n",
    "                \"affinity_sum\": {}\n",
    "            }\n",
    "        tfs[tf][\"target_genes\"][assay] = df_tg[tf].to_dict()\n",
    "\n",
    "for file in deseq2_differential_dir.glob(\"*.deseq2.results.tsv\"):\n",
    "    pair_string = file.stem.split(\".\")[0]\n",
    "    pairings.add(pair_string)\n",
    "\n",
    "    df_deseq2 = pd.read_csv(file, sep=\"\\t\", index_col=0)\n",
    "\n",
    "    for tf in tfs:\n",
    "        tf_row = df_deseq2.loc[tf]\n",
    "        tfs[tf][\"differential_expression\"][pair_string] = {\n",
    "            \"baseMean\": tf_row[\"baseMean\"],\n",
    "            \"log2FoldChange\": tf_row[\"log2FoldChange\"],\n",
    "            \"lfcSE\": tf_row[\"lfcSE\"],\n",
    "            \"pvalue\": tf_row[\"pvalue\"],\n",
    "        }\n",
    "\n",
    "json.dump(ranking, open(assets_dir / \"ranking.json\", \"w\"), indent=4)\n",
    "\n",
    "assays = list(ranking.keys())\n",
    "metadata[\"assays\"] = assays\n",
    "\n",
    "conditions = list(metadata[\"conditions\"].keys())\n",
    "\n",
    "tf_dir = public_dir / \"transcription_factors\"\n",
    "tf_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "df_tpm = pd.read_csv(tpm_dir / \"counts.tpm.tsv\", sep=\"\\t\", index_col=0).T\n",
    "df_counts = pd.read_csv(raw_counts_dir / \"counts.counts_filtered.tsv\", sep=\"\\t\", index_col=0).T\n",
    "\n",
    "# Create condition-to-sample mapping for restructuring data\n",
    "condition_to_samples = metadata[\"conditions\"]\n",
    "\n",
    "assay_pairing_tf_coefficients = defaultdict(dict)\n",
    "\n",
    "for pairing, assay in product(pairings, assays):\n",
    "    df_path = regression_coefficients_dir / f\"{pairing}_{assay}_dynamite_regression_coefficients.txt\"\n",
    "    if not df_path.exists():\n",
    "        continue\n",
    "    df_coefficients = pd.read_csv(df_path, sep=\"\\t\", index_col=0)\n",
    "    # Drop rows where all values are NaN\n",
    "    df_coefficients = df_coefficients.dropna(how=\"all\")\n",
    "\n",
    "    if len(df_coefficients) > 0:\n",
    "        assay_pairing_tf_coefficients[pairing][assay] = df_coefficients[\"value\"].to_dict()\n",
    "\n",
    "    affinity_ratio_path = affinity_ratio_dir / f\"{pairing}_{assay}.tsv\"\n",
    "    if affinity_ratio_path.exists():\n",
    "        df_affinity_ratio = pd.read_csv(affinity_ratio_path, sep=\"\\t\", index_col=0)\n",
    "        for tf in tfs:\n",
    "            tfs[tf][\"affinity_ratio\"][pairing] = {}\n",
    "            if tf not in df_affinity_ratio.columns:\n",
    "                continue\n",
    "            tfs[tf][\"affinity_ratio\"][pairing][assay] = df_affinity_ratio[tf].to_dict()\n",
    "\n",
    "    affinity_sum_path = affinity_sum_dir / f\"{pairing}_{assay}.tsv\"\n",
    "    if affinity_sum_path.exists():\n",
    "        df_affinity_sum = pd.read_csv(affinity_sum_path, sep=\"\\t\", index_col=0)\n",
    "        for tf in tfs:\n",
    "            tfs[tf][\"affinity_sum\"][pairing] = {}\n",
    "            if tf not in df_affinity_sum.columns:\n",
    "                continue\n",
    "            tfs[tf][\"affinity_sum\"][pairing][assay] = df_affinity_sum[tf].to_dict()\n",
    "\n",
    "json.dump(assay_pairing_tf_coefficients, open(assets_dir / \"regression_coefficients.json\", \"w\"), indent=4)\n",
    "\n",
    "for condition, assay in product(conditions, assays):\n",
    "    df_path = affinities_dir / f\"{condition}_{assay}.agg_affinities.tsv\"\n",
    "\n",
    "    if not df_path.exists():\n",
    "        continue\n",
    "    df_affinities = pd.read_csv(df_path, sep=\"\\t\", index_col=0)\n",
    "\n",
    "    for tf in tfs:\n",
    "        if tf not in df_affinities.columns:\n",
    "            continue\n",
    "        if condition not in tfs[tf][\"tg_affinities\"]:\n",
    "            tfs[tf][\"tg_affinities\"][condition] = {}\n",
    "        tfs[tf][\"tg_affinities\"][condition][assay] = df_affinities[tf].to_dict()\n",
    "\n",
    "for tf in tfs:\n",
    "    # Restructure TPM data: condition -> sample -> value\n",
    "    tfs[tf][\"tpm\"] = {}\n",
    "    for condition, samples in condition_to_samples.items():\n",
    "        tfs[tf][\"tpm\"][condition] = {}\n",
    "        for sample in samples:\n",
    "            if sample in df_tpm.index:\n",
    "                tfs[tf][\"tpm\"][condition][sample] = df_tpm.loc[sample, tf]\n",
    "    \n",
    "    # Restructure counts data: condition -> sample -> value\n",
    "    tfs[tf][\"counts\"] = {}\n",
    "    for condition, samples in condition_to_samples.items():\n",
    "        tfs[tf][\"counts\"][condition] = {}\n",
    "        for sample in samples:\n",
    "            if sample in df_counts.index:\n",
    "                tfs[tf][\"counts\"][condition][sample] = df_counts.loc[sample, tf]\n",
    "\n",
    "    json.dump(tfs[tf], open(tf_dir / f\"{tf}.json\", \"w\"), indent=4)\n",
    "\n",
    "metadata[\"transcription_factors\"] = list(tfs.keys())\n",
    "\n",
    "json.dump(metadata, open(assets_dir / \"metadata.json\", \"w\"), indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "single-cell",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
